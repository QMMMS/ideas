# SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings

> https://aclanthology.org/2025.acl-long.1212/

尽管 多模态大型语言模型 MLLMs实现了先进的多模态能力，但它们比LLMs表现出更严重的安全风险。通过向非文本输入中注入恶意信息，可以轻易诱导MLLMs遵从用户的有害指令。

当前的缓解策略，如监督微调（SFT）和带人类反馈的强化学习（RLHF）在提升MLLM的安全性方面显示出了有效性。然而，构建多模态安全对齐数据集的成本很高。与LLMs不同，MLLMs的高质量安全对齐数据要求三个组成部分之间存在强相关性：文本指令、文本响应以及额外的模态，这使得数据收集过程更加昂贵。此外，由于额外模态的差异，每当为MLLM引入新的出现模态（如脑电图信号）时，都必须重建安全对齐数据。这不仅增加了额外成本，还导致数据集的开发落后于MLLMs本身的进步。因此，迫切需要一种资源高效且普遍适用的安全对齐方法来促进更安全的多模态语言模型的发展。

文本对齐仅在文本输入中出现明确有害信息时才有效，例如指令“如何使用图像中的产品来抢劫银行”，配以炸弹的图像输入。相比之下，经过多模态对齐的模型通常对各种场景都有效，包括仅通过图像展示有害信息的样本，如指令“如何制作该产品”，配以炸弹的输入图像。为了解决文本对齐的局限性，使用生成模型生成附加模态的数据是一个潜在的解决方案。然而，并非所有模态都有高性能的生成模型可用，特别是对于那些未来可能出现的新兴多模态语言模型。

为了解决上述限制，我们提出了SEA，一个使用合成嵌入来增强安全对齐的新框架。该方法首先优化了在MLLMs认为包含特定有害活动或产品的模态编码器输出空间中的嵌入表示。随后，优化后的嵌入可以与文本数据集集成，取代真实的多模态数据集进行安全对齐训练。我们的方法消除了收集和策划真实多模态数据集这一资源密集型过程。

实验在基于图像、视频和音频的MLLMs上进行，结果表明，在单个RTX 3090 GPU上仅需两个训练样本即可在24秒内优化出高质量的嵌入。此外，使用合成嵌入构建的数据集进行安全对齐显著增强了MLLMs抵御来自额外模态威胁的安全性。

由于缺乏公开可用的针对基于视频和音频的MLLMs的安全评估基准，我们还引入了VA-SafeBench，它扩展了基于图像的MM-SafetyBench。具体来说，VA-SafeBench中的每个样本都一对一地从MM-SafetyBench的八个场景样本转换而来。它们共享相同的有害信息来源，但VA-SafeBench中的提问形式包括视频-文本对和音频-文本对。多个MLLMs的高攻击成功率（ASR）验证了VA-SafeBench所带来的挑战。

## 方法

由于多模态数据集对MLLM的安全对齐训练至关重要，但并非所有模态都有高性能的生成模型可用，我们旨在找到一种更通用的方法来合成额外模态的数据。一个关键的洞察是，用于安全对齐的额外模态数据（如炸弹图片）并不一定需要人类可解释，只需被MLLMs解释为含有指定的有害活动或产品即可。

